
default_system_prompt_lang="en"

[llm_models.ollama]
provider = "ollama"
#base_url = "http://172.16.10.151:11434"
base_url = "http://172.235.61.221:11555"
model_name = "gpt-oss:20b"
temperature = 0

[llm_models.deepseek]
provider = "deepseek"
base_url = "https://api.deepseek.com/v1"
model_name = "deepseek-chat"
api_key = "sk-xxxxxxxxxx"
temperature = 0.7


[llm_models.openai]
provider = "openai"
base_url = "https://api.openai.com/v1"
model_name = "gpt-4-turbo-preview"
temperature = 0.7
max_tokens = 4096





[llm_models.gemini]
provider = "gemini"
base_url = "https://generativelanguage.googleapis.com/v1beta"
model_name = "gemini-1.5-pro"
#temperature = 0.7
#max_tokens = 4096

[llm_models.anthropic]
provider = "anthropic"
base_url = "https://api.anthropic.com"
model_name = "claude-3-opus-20240229"
temperature = 0.7
#max_tokens = 4096

[llm_models.qwen]
provider = "qwen"
base_url = "https://dashscope.aliyuncs.com/api/v1"
model_name = "qwen-turbo"
##temperature = 0.7
#max_tokens = 2048


[llm_models.huggingface]
provider = "huggingface"
base_url = "https://api-inference.huggingface.co"
model_name = "microsoft/DialoGPT-medium"
#temperature = 0.7
#max_tokens = 2048


[llm_models.xai]
provider = "xai"
base_url = "https://api.x.ai/v1"
model_name = "grok-beta"
#temperature = 0.7
#max_tokens = 4096
